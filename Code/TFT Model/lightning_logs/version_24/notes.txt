版本: version_24
設定: encoder_length=120, train_fraction=0.8, hidden_size=48, hidden_continuous_size=24, dropout=0.2, weight_decay=5e-4, lr=8e-4, pos_weight=0.5, threshold_grid=0.2-0.95 step 0.01, monitor=val_best_f1, early_stop=15, train_eval_batches=None。
結果: best_val_f1=0.7084@epoch20(th=0.20), acc=0.5589, precision=0.5498, recall=0.9957, prediction_rate=0.975, roc_auc=0.495, pr_auc=0.540，last_30_acc=0.60。比 version_22 小幅提升 acc(+0.016) 與 F1(+0.007) 但仍低於目標。
觀察: pos_weight 下調與模型縮小後仍大量預測正類(~97%)，最佳門檻降到 0.2，AUC 仍 <0.5 顯示排序能力差；val_loss 有下降但分類訊號弱，提升主要靠閾值調整而非 logits 可分性。
下一步: 1) 嘗試 focal loss (gamma≈2, alpha≈0.35-0.45) 或 BCE + label smoothing 以抑制易正類並強化難例分辨；2) 拉高閾值掃描到 0.99 並以 val_best_accuracy 或 pr_auc 作為監控，觀察 precision/acc 是否上升；3) 再縮小模型/encoder_length(60-90) 或增加技術面特徵(均線、波動度、動能指標)並移除弱 calendar 特徵，提升 AUC 後再調閾值。
